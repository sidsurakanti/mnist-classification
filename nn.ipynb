{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5c4332c-4bf8-44fb-8c0c-003f19a9b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c9d0fa5-5908-4af5-b1b5-c4bea026356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./dataset/train.csv\")\n",
    "test = pd.read_csv(\"./dataset/test.csv\")\n",
    "\n",
    "train = np.array(train)\n",
    "m, n = train.shape # training examples (m), pixels (784)\n",
    "np.random.shuffle(train)\n",
    "\n",
    "train = train.T\n",
    "X = train[1:] / 255.0 # images (784, m)\n",
    "y = train[0] # labels (1, m)\n",
    "\n",
    "test = np.array(test)\n",
    "test = test.T\n",
    "y_test, X_test = test[0], test[1:].T / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa24fc44-a03c-40a5-bb95-0270dfa2936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def dReLU(Z):\n",
    "    return (Z > 0).astype(float)\n",
    "\n",
    "def softmax(Z2):\n",
    "    expZ = np.exp(Z2 - np.max(Z2, axis=0, keepdims=True))\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
    "\n",
    "def one_hot(y):\n",
    "    m = y.shape[0]\n",
    "    arr = np.zeros((10, m))\n",
    "    arr[y, np.arange(m)] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "902ce482-0d51-4d5c-b30d-f05696196d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(W1, b1, W2, b2, X):\n",
    "    Z1 = W1 @ X + b1 # (10, m)\n",
    "    A1 = ReLU(Z1) # hidden layer 1 (10, m)\n",
    "    Z2 = W2 @ A1 + b2 # logits, (10, m)\n",
    "    A2 = softmax(Z2) # output layer normalized based on probability (10, m)\n",
    "\n",
    "    return A2, Z2, A1, Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f15935-9af3-4aaf-8e5c-9477fec2935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(A2, y):\n",
    "    return (A2 - one_hot(y))**2 * 1/m\n",
    "\n",
    "def backward_pass(A2, Z2, A1, Z1, W2, W1, y):\n",
    "    # chain rule dC/dW2, dC/db2\n",
    "    dZ2 = 2 * (A2 - one_hot(y)) # dC wrt dZ2\n",
    "    dW2 = dZ2 @ A1.T / m # (10, m) * (m, 10).T => (10, 10), dZ2 wrt dW2\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m # (10, 1)\n",
    "\n",
    "    # chain rule dC/dW1, dC/db1\n",
    "    dA1 = W2.T @ dZ2 # (10, 10) * (10, m) => (10, m)\n",
    "    dZ1 = dA1 * dReLU(Z1) # => (10, m)\n",
    "    dW1 = dZ1 @ X.T / m  # (10, m) * (m, 784) => (10, 784)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m # (10, 1)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(dW1, db1, dW2, db2, W2, b2, W1, b1):\n",
    "    alpha = 0.1 # learning rate\n",
    "    W2 -= dW2 * alpha\n",
    "    b2 -= db2 * alpha\n",
    "    W1 -= dW1 * alpha\n",
    "    b1 -= db1 * alpha\n",
    "\n",
    "    return W1, b1, W2, b1\n",
    "\n",
    "def get_accuracy(A2, Y):\n",
    "    predictions = np.argmax(A2, axis=0)\n",
    "    return np.mean(predictions == y) * 100\n",
    "\n",
    "def gradient_descent(X, Y, iterations):\n",
    "    W1, b1, W2, b2 = params()\n",
    "    for i in range(iterations):\n",
    "        A2, Z2, A1, Z1 = forward_pass(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_pass(A2, Z2, A1, Z1, W2, W1, Y)\n",
    "        W1, b1, W2, b2 = update_params(dW1, db1, dW2, db2, W2, b2, W1, b1)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\"Iteration:\", i)\n",
    "            print(\"Accuracy:\", round(get_accuracy(A2, Y), 2))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "966c2902-c3b3-40ec-80ca-b1723351053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Accuracy: 8.35\n",
      "Iteration: 50\n",
      "Accuracy: 63.09\n",
      "Iteration: 100\n",
      "Accuracy: 74.9\n",
      "Iteration: 150\n",
      "Accuracy: 80.52\n",
      "Iteration: 200\n",
      "Accuracy: 83.37\n",
      "Iteration: 250\n",
      "Accuracy: 85.13\n",
      "Iteration: 300\n",
      "Accuracy: 86.21\n",
      "Iteration: 350\n",
      "Accuracy: 87.02\n",
      "Iteration: 400\n",
      "Accuracy: 87.58\n",
      "Iteration: 450\n",
      "Accuracy: 88.07\n",
      "Iteration: 500\n",
      "Accuracy: 88.49\n",
      "Iteration: 550\n",
      "Accuracy: 88.8\n",
      "Iteration: 600\n",
      "Accuracy: 89.08\n",
      "Iteration: 650\n",
      "Accuracy: 89.34\n",
      "Iteration: 700\n",
      "Accuracy: 89.54\n",
      "Iteration: 750\n",
      "Accuracy: 89.75\n",
      "Iteration: 800\n",
      "Accuracy: 89.94\n",
      "Iteration: 850\n",
      "Accuracy: 90.1\n",
      "Iteration: 900\n",
      "Accuracy: 90.26\n",
      "Iteration: 950\n",
      "Accuracy: 90.42\n",
      "Iteration: 1000\n",
      "Accuracy: 90.56\n",
      "Iteration: 1050\n",
      "Accuracy: 90.69\n",
      "Iteration: 1100\n",
      "Accuracy: 90.79\n",
      "Iteration: 1150\n",
      "Accuracy: 90.89\n",
      "Iteration: 1200\n",
      "Accuracy: 90.94\n",
      "Iteration: 1250\n",
      "Accuracy: 91.02\n",
      "Iteration: 1300\n",
      "Accuracy: 91.1\n",
      "Iteration: 1350\n",
      "Accuracy: 91.18\n",
      "Iteration: 1400\n",
      "Accuracy: 91.23\n",
      "Iteration: 1450\n",
      "Accuracy: 91.3\n",
      "Iteration: 1500\n",
      "Accuracy: 91.37\n",
      "Iteration: 1550\n",
      "Accuracy: 91.45\n",
      "Iteration: 1600\n",
      "Accuracy: 91.52\n",
      "Iteration: 1650\n",
      "Accuracy: 91.57\n",
      "Iteration: 1700\n",
      "Accuracy: 91.64\n",
      "Iteration: 1750\n",
      "Accuracy: 91.7\n",
      "Iteration: 1800\n",
      "Accuracy: 91.77\n",
      "Iteration: 1850\n",
      "Accuracy: 91.81\n",
      "Iteration: 1900\n",
      "Accuracy: 91.87\n",
      "Iteration: 1950\n",
      "Accuracy: 91.93\n",
      "Iteration: 2000\n",
      "Accuracy: 91.97\n",
      "Iteration: 2050\n",
      "Accuracy: 92.0\n",
      "Iteration: 2100\n",
      "Accuracy: 92.05\n",
      "Iteration: 2150\n",
      "Accuracy: 92.08\n",
      "Iteration: 2200\n",
      "Accuracy: 92.14\n",
      "Iteration: 2250\n",
      "Accuracy: 92.17\n",
      "Iteration: 2300\n",
      "Accuracy: 92.22\n",
      "Iteration: 2350\n",
      "Accuracy: 92.26\n",
      "Iteration: 2400\n",
      "Accuracy: 92.29\n",
      "Iteration: 2450\n",
      "Accuracy: 92.33\n",
      "Iteration: 2500\n",
      "Accuracy: 92.36\n",
      "Iteration: 2550\n",
      "Accuracy: 92.4\n",
      "Iteration: 2600\n",
      "Accuracy: 92.43\n",
      "Iteration: 2650\n",
      "Accuracy: 92.48\n",
      "Iteration: 2700\n",
      "Accuracy: 92.52\n",
      "Iteration: 2750\n",
      "Accuracy: 92.55\n",
      "Iteration: 2800\n",
      "Accuracy: 92.59\n",
      "Iteration: 2850\n",
      "Accuracy: 92.63\n",
      "Iteration: 2900\n",
      "Accuracy: 92.68\n",
      "Iteration: 2950\n",
      "Accuracy: 92.7\n",
      "Iteration: 3000\n",
      "Accuracy: 92.72\n",
      "Iteration: 3050\n",
      "Accuracy: 92.74\n",
      "Iteration: 3100\n",
      "Accuracy: 92.74\n",
      "Iteration: 3150\n",
      "Accuracy: 92.76\n",
      "Iteration: 3200\n",
      "Accuracy: 92.8\n",
      "Iteration: 3250\n",
      "Accuracy: 92.82\n",
      "Iteration: 3300\n",
      "Accuracy: 92.85\n",
      "Iteration: 3350\n",
      "Accuracy: 92.88\n",
      "Iteration: 3400\n",
      "Accuracy: 92.9\n",
      "Iteration: 3450\n",
      "Accuracy: 92.93\n",
      "Iteration: 3500\n",
      "Accuracy: 92.95\n",
      "Iteration: 3550\n",
      "Accuracy: 92.97\n",
      "Iteration: 3600\n",
      "Accuracy: 92.99\n",
      "Iteration: 3650\n",
      "Accuracy: 93.02\n",
      "Iteration: 3700\n",
      "Accuracy: 93.04\n",
      "Iteration: 3750\n",
      "Accuracy: 93.04\n",
      "Iteration: 3800\n",
      "Accuracy: 93.05\n",
      "Iteration: 3850\n",
      "Accuracy: 93.07\n",
      "Iteration: 3900\n",
      "Accuracy: 93.1\n",
      "Iteration: 3950\n",
      "Accuracy: 93.12\n",
      "Iteration: 4000\n",
      "Accuracy: 93.14\n",
      "Iteration: 4050\n",
      "Accuracy: 93.16\n",
      "Iteration: 4100\n",
      "Accuracy: 93.17\n",
      "Iteration: 4150\n",
      "Accuracy: 93.2\n",
      "Iteration: 4200\n",
      "Accuracy: 93.22\n",
      "Iteration: 4250\n",
      "Accuracy: 93.23\n",
      "Iteration: 4300\n",
      "Accuracy: 93.24\n",
      "Iteration: 4350\n",
      "Accuracy: 93.25\n",
      "Iteration: 4400\n",
      "Accuracy: 93.27\n",
      "Iteration: 4450\n",
      "Accuracy: 93.3\n",
      "Iteration: 4500\n",
      "Accuracy: 93.32\n",
      "Iteration: 4550\n",
      "Accuracy: 93.34\n",
      "Iteration: 4600\n",
      "Accuracy: 93.36\n",
      "Iteration: 4650\n",
      "Accuracy: 93.38\n",
      "Iteration: 4700\n",
      "Accuracy: 93.4\n",
      "Iteration: 4750\n",
      "Accuracy: 93.41\n",
      "Iteration: 4800\n",
      "Accuracy: 93.42\n",
      "Iteration: 4850\n",
      "Accuracy: 93.43\n",
      "Iteration: 4900\n",
      "Accuracy: 93.44\n",
      "Iteration: 4950\n",
      "Accuracy: 93.45\n",
      "Iteration: 5000\n",
      "Accuracy: 93.47\n",
      "Iteration: 5050\n",
      "Accuracy: 93.49\n",
      "Iteration: 5100\n",
      "Accuracy: 93.51\n",
      "Iteration: 5150\n",
      "Accuracy: 93.52\n",
      "Iteration: 5200\n",
      "Accuracy: 93.53\n",
      "Iteration: 5250\n",
      "Accuracy: 93.54\n",
      "Iteration: 5300\n",
      "Accuracy: 93.58\n",
      "Iteration: 5350\n",
      "Accuracy: 93.59\n",
      "Iteration: 5400\n",
      "Accuracy: 93.61\n",
      "Iteration: 5450\n",
      "Accuracy: 93.63\n",
      "Iteration: 5500\n",
      "Accuracy: 93.64\n",
      "Iteration: 5550\n",
      "Accuracy: 93.65\n",
      "Iteration: 5600\n",
      "Accuracy: 93.67\n",
      "Iteration: 5650\n",
      "Accuracy: 93.68\n",
      "Iteration: 5700\n",
      "Accuracy: 93.69\n",
      "Iteration: 5750\n",
      "Accuracy: 93.71\n",
      "Iteration: 5800\n",
      "Accuracy: 93.71\n",
      "Iteration: 5850\n",
      "Accuracy: 93.72\n",
      "Iteration: 5900\n",
      "Accuracy: 93.75\n",
      "Iteration: 5950\n",
      "Accuracy: 93.75\n",
      "Iteration: 6000\n",
      "Accuracy: 93.79\n",
      "Iteration: 6050\n",
      "Accuracy: 93.79\n",
      "Iteration: 6100\n",
      "Accuracy: 93.81\n",
      "Iteration: 6150\n",
      "Accuracy: 93.82\n",
      "Iteration: 6200\n",
      "Accuracy: 93.84\n",
      "Iteration: 6250\n",
      "Accuracy: 93.85\n",
      "Iteration: 6300\n",
      "Accuracy: 93.85\n",
      "Iteration: 6350\n",
      "Accuracy: 93.87\n",
      "Iteration: 6400\n",
      "Accuracy: 93.88\n",
      "Iteration: 6450\n",
      "Accuracy: 93.88\n",
      "Iteration: 6500\n",
      "Accuracy: 93.89\n",
      "Iteration: 6550\n",
      "Accuracy: 93.9\n",
      "Iteration: 6600\n",
      "Accuracy: 93.91\n",
      "Iteration: 6650\n",
      "Accuracy: 93.91\n",
      "Iteration: 6700\n",
      "Accuracy: 93.92\n",
      "Iteration: 6750\n",
      "Accuracy: 93.93\n",
      "Iteration: 6800\n",
      "Accuracy: 93.94\n",
      "Iteration: 6850\n",
      "Accuracy: 93.96\n",
      "Iteration: 6900\n",
      "Accuracy: 93.97\n",
      "Iteration: 6950\n",
      "Accuracy: 93.98\n",
      "Iteration: 7000\n",
      "Accuracy: 93.98\n",
      "Iteration: 7050\n",
      "Accuracy: 93.99\n",
      "Iteration: 7100\n",
      "Accuracy: 94.01\n",
      "Iteration: 7150\n",
      "Accuracy: 94.03\n",
      "Iteration: 7200\n",
      "Accuracy: 94.04\n",
      "Iteration: 7250\n",
      "Accuracy: 94.06\n",
      "Iteration: 7300\n",
      "Accuracy: 94.07\n",
      "Iteration: 7350\n",
      "Accuracy: 94.09\n",
      "Iteration: 7400\n",
      "Accuracy: 94.1\n",
      "Iteration: 7450\n",
      "Accuracy: 94.12\n",
      "Iteration: 7500\n",
      "Accuracy: 94.13\n",
      "Iteration: 7550\n",
      "Accuracy: 94.15\n",
      "Iteration: 7600\n",
      "Accuracy: 94.17\n",
      "Iteration: 7650\n",
      "Accuracy: 94.18\n",
      "Iteration: 7700\n",
      "Accuracy: 94.18\n",
      "Iteration: 7750\n",
      "Accuracy: 94.17\n",
      "Iteration: 7800\n",
      "Accuracy: 94.18\n",
      "Iteration: 7850\n",
      "Accuracy: 94.18\n",
      "Iteration: 7900\n",
      "Accuracy: 94.2\n",
      "Iteration: 7950\n",
      "Accuracy: 94.21\n",
      "Iteration: 8000\n",
      "Accuracy: 94.22\n",
      "Iteration: 8050\n",
      "Accuracy: 94.24\n",
      "Iteration: 8100\n",
      "Accuracy: 94.24\n",
      "Iteration: 8150\n",
      "Accuracy: 94.25\n",
      "Iteration: 8200\n",
      "Accuracy: 94.26\n",
      "Iteration: 8250\n",
      "Accuracy: 94.26\n",
      "Iteration: 8300\n",
      "Accuracy: 94.27\n",
      "Iteration: 8350\n",
      "Accuracy: 94.28\n",
      "Iteration: 8400\n",
      "Accuracy: 94.28\n",
      "Iteration: 8450\n",
      "Accuracy: 94.3\n",
      "Iteration: 8500\n",
      "Accuracy: 94.29\n",
      "Iteration: 8550\n",
      "Accuracy: 94.3\n",
      "Iteration: 8600\n",
      "Accuracy: 94.32\n",
      "Iteration: 8650\n",
      "Accuracy: 94.34\n",
      "Iteration: 8700\n",
      "Accuracy: 94.34\n",
      "Iteration: 8750\n",
      "Accuracy: 94.34\n",
      "Iteration: 8800\n",
      "Accuracy: 94.36\n",
      "Iteration: 8850\n",
      "Accuracy: 94.37\n",
      "Iteration: 8900\n",
      "Accuracy: 94.37\n",
      "Iteration: 8950\n",
      "Accuracy: 94.38\n",
      "Iteration: 9000\n",
      "Accuracy: 94.4\n",
      "Iteration: 9050\n",
      "Accuracy: 94.41\n",
      "Iteration: 9100\n",
      "Accuracy: 94.42\n",
      "Iteration: 9150\n",
      "Accuracy: 94.42\n",
      "Iteration: 9200\n",
      "Accuracy: 94.43\n",
      "Iteration: 9250\n",
      "Accuracy: 94.44\n",
      "Iteration: 9300\n",
      "Accuracy: 94.44\n",
      "Iteration: 9350\n",
      "Accuracy: 94.46\n",
      "Iteration: 9400\n",
      "Accuracy: 94.46\n",
      "Iteration: 9450\n",
      "Accuracy: 94.46\n",
      "Iteration: 9500\n",
      "Accuracy: 94.47\n",
      "Iteration: 9550\n",
      "Accuracy: 94.48\n",
      "Iteration: 9600\n",
      "Accuracy: 94.49\n",
      "Iteration: 9650\n",
      "Accuracy: 94.49\n",
      "Iteration: 9700\n",
      "Accuracy: 94.49\n",
      "Iteration: 9750\n",
      "Accuracy: 94.5\n",
      "Iteration: 9800\n",
      "Accuracy: 94.52\n",
      "Iteration: 9850\n",
      "Accuracy: 94.52\n",
      "Iteration: 9900\n",
      "Accuracy: 94.53\n",
      "Iteration: 9950\n",
      "Accuracy: 94.53\n"
     ]
    }
   ],
   "source": [
    "trainedWeights = gradient_descent(X, y, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59de5556-ca87-431e-b957-748d473b4b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2\n",
      "Label: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict(i, W1, b1, W2, b2):\n",
    "    A2, _, _, _ = forward_pass(W1, b1, W2, b2, X_test.T)\n",
    "    prediction = np.argmax(A2, axis=0)[i]\n",
    "    label = y_test[i]\n",
    "    plt.imshow(X_test[i].reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.axis(False)\n",
    "    print(\"Prediction:\", int(prediction))\n",
    "    print(\"Label:\", int(label))\n",
    "\n",
    "predict(randint(1, 10000), *trainedWeights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
